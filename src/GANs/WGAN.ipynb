{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WGAN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1q-rQFRyszIveG2B-_AuQ4YxhCRhZhBDO","authorship_tag":"ABX9TyOzJ8rZi1BGUd3sUPUhYSdm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qw0YEi0_fXRe","colab_type":"code","cellView":"form","outputId":"900f4a6d-091f-4f0e-aedc-740244644681","executionInfo":{"status":"ok","timestamp":1583881045519,"user_tz":-60,"elapsed":1471,"user":{"displayName":"ilyas moutawwakil","photoUrl":"","userId":"11714869551917393786"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#@title Colab Specifications\n","%matplotlib inline\n","%tensorflow_version 2.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oLlgev7cPsgK","cellView":"form","outputId":"315c18c2-8329-44a8-bea5-ad9ea387a4d5","executionInfo":{"status":"ok","timestamp":1583881046574,"user_tz":-60,"elapsed":2483,"user":{"displayName":"ilyas moutawwakil","photoUrl":"","userId":"11714869551917393786"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#@title Mount at Google Drive\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/My Drive/Colab Notebooks')\n","print()\n","print(f\"Current directory : {os.getcwd()}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","Current directory : /content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G6ndpX_EfsvH","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Data preprocessing\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from pathlib import Path\n","\n","tfds.disable_progress_bar()\n","\n","DATASET = \"mnist\" #@param [\"mnist\", \"fashion_mnist\", \"cifar10\"] {allow-input: true}\n","\n","# load dataset\n","tf_dataset, info = tfds.load(DATASET, split=\"train\", batch_size=-1, with_info=True)\n","np_dataset = tfds.as_numpy(tf_dataset)\n","train_images, train_labels = np_dataset[\"image\"].astype('float32'), np_dataset[\"label\"]\n","train_images = (train_images - 127.5) / 127.5\n","\n","PATHS = [\n","         'plots/%s/WGAN/' % DATASET.upper(),\n","         'models/%s/WGAN/' % DATASET.upper(),\n","         'logs/%s/WGAN/' % DATASET.upper()      \n","          ]\n","for path in PATHS:\n","    Path(path).mkdir(parents=True, exist_ok=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Ljgeub3e3Gy","colab_type":"code","cellView":"form","outputId":"aa898cbd-d940-4500-f2b6-dd23427aa414","executionInfo":{"status":"ok","timestamp":1583881053210,"user_tz":-60,"elapsed":9060,"user":{"displayName":"ilyas moutawwakil","photoUrl":"","userId":"11714869551917393786"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["#@title Data Visualization\n","\n","from matplotlib import pyplot\n","from pylab import rcParams\n","\n","PLOT_SIZE = 20 #@param {type:\"integer\"}\n","\n","rcParams['figure.figsize'] = PLOT_SIZE, PLOT_SIZE\n","\n","VIS_LINES = 1 #@param {type:\"integer\"}\n","VIS_ROWS = 10 #@param {type:\"integer\"}\n","\n","# plot images from the training dataset\n","for i in range(VIS_LINES*VIS_ROWS):\n","    # define subplot\n","    pyplot.subplot(VIS_LINES, VIS_ROWS, 1 + i)\n","    # turn off axis\n","    pyplot.axis('off')\n","    # plot raw pixel data\n","    pyplot.imshow(tf.squeeze((train_images[i] + 1) / 2), cmap='gray_r')\n","pyplot.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAlz6V/pRJ0AAAAASUVORK5CYII=\n","text/plain":["<Figure size 1440x1440 with 10 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","cellView":"both","id":"sI3YVysx9qcx","colab":{}},"source":["#@title Best WGAN Model\n","\n","from tensorflow.keras.models import Sequential, Model\n","\n","class WGAN(Model):\n","    \"\"\"\n","    Honestly, the best way to implement a model\n","    \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        \"\"\"\n","        initialize model with its super's features and methods\n","        \"\"\"\n","\n","        super(WGAN, self).__init__()\n","        self.__dict__.update(kwargs)\n","        self.gen = Sequential(self.gen)\n","        self.disc = Sequential(self.disc)\n","\n","    @tf.function\n","    def generate(self, z):\n","        \"\"\"\n","        passes through the generator network\n","        \"\"\"\n","\n","        return self.gen(z)\n","\n","    @tf.function\n","    def discrimenate(self, x):\n","        \"\"\"\n","        passes through the discrimenator network\n","        \"\"\"\n","\n","        return self.disc(x)\n","\n","    @tf.function\n","    def compute_disc_loss(self, x, batch_size):\n","        \"\"\"\n","        passes through the network and computes loss\n","        \"\"\"\n","\n","        # generating noise from a uniform distribution\n","        z_samp = tf.random.normal([batch_size, 1, 1, self.z_size])\n","        # run noise through generator\n","        x_gen = self.generate(z_samp)\n","        # discrimenate x and x_gen\n","        logits_x = self.discrimenate(x)\n","        logits_x_gen = self.discrimenate(x_gen)\n","        # pondered loss : note that logits_x are multipied by 1 and logits_x_gen are multiplied by -1, e.g. wasserstein loss\n","        disc_loss = (tf.reduce_mean(logits_x) - tf.reduce_mean(logits_x_gen))\n","\n","        return disc_loss\n","    \n","    @tf.function\n","    def compute_gen_loss(self, batch_size):\n","        \"\"\"\n","        passes through the network and computes loss\n","        \"\"\"\n","\n","        # generating noise from a uniform distribution\n","        z_samp = tf.random.normal([batch_size, 1, 1, self.z_size])\n","        # run noise through generator\n","        x_gen = self.generate(z_samp)\n","        # discrimenate x_gen\n","        logits_x_gen = self.discrimenate(x_gen)\n","        # losses of fake with label \"1\"\n","        gen_loss = tf.reduce_mean(logits_x_gen)\n","\n","        return gen_loss\n","\n","    @tf.function\n","    def compute_disc_gradients(self, x, batch_size):\n","        \"\"\"\n","        passes through the network and computes loss\n","        \"\"\"\n","\n","        ### compute loss\n","        with tf.GradientTape() as disc_tape:\n","            disc_loss = self.compute_disc_loss(x, batch_size)\n","            # compute gradients\n","            disc_gradients = disc_tape.gradient(disc_loss, self.disc.trainable_variables)\n","\n","        return disc_gradients, disc_loss\n","    \n","    @tf.function\n","    def compute_gen_gradients(self, batch_size):\n","        \"\"\"\n","        passes through the network and computes loss\n","        \"\"\"\n","\n","        ### compute loss\n","        with tf.GradientTape() as gen_tape:\n","            gen_loss = self.compute_gen_loss(batch_size)\n","            # compute gradients\n","            gen_gradients = gen_tape.gradient(gen_loss, self.gen.trainable_variables)\n","        \n","        return gen_gradients, gen_loss\n","\n","    @tf.function\n","    def train_disc(self, train_x, batch_size):\n","\n","        # calculate gradients and loss\n","        disc_gradients, disc_loss = self.compute_disc_gradients(train_x, batch_size)\n","        # apply gradients\n","        self.disc_optimizer.apply_gradients(zip(disc_gradients, self.disc.trainable_variables))\n","        \n","        return disc_loss\n","    \n","    @tf.function\n","    def train_gen(self, batch_size):\n","\n","        # calculate gradients and loss\n","        gen_gradients, gen_loss = self.compute_gen_gradients(batch_size)\n","        # apply gradients\n","        self.gen_optimizer.apply_gradients(zip(gen_gradients, self.gen.trainable_variables))\n","        \n","        return gen_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4R7CivfN-JRl","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Defining the Generator and the Discrimenator sub-models\n","\n","from tensorflow.keras.layers import UpSampling2D, Conv2D, BatchNormalization, \\\n","                                    Activation, ZeroPadding2D, Input, Dense,  \\\n","                                    Reshape, Flatten, Dropout, LeakyReLU, Add\n","\n","from tensorflow.keras.initializers import RandomNormal\n","from tensorflow.keras.constraints import Constraint\n","\n","UP_SAMPLING_LAYERS = 2 #@param {type:\"integer\"}\n","INIT_KERNELS = 128 #@param {type:\"integer\"}\n","Z_SIZE = 100    #@param {type:\"integer\"}\n","\n","DIMS = train_images[0].shape\n","IMAGE_CHANNELS = DIMS[2]\n","INIT_IMAGE_SIZE = int(DIMS[0] / 2**UP_SAMPLING_LAYERS)\n","\n","\n","# clip model weights to a given hypercube\n","class ClipConstraint(Constraint):\n","    # set clip value when initialized\n","    def __init__(self, clip_value):\n","        self.clip_value = clip_value\n","\n","    # clip model weights to hypercube\n","    def __call__(self, weights):\n","        return tf.clip_by_value(weights, -self.clip_value, self.clip_value)\n","\n","    # get the config\n","    def get_config(self):\n","        return {'clip_value': self.clip_value}\n","\n","const = ClipConstraint(0.01)\n","init = RandomNormal(stddev=0.02)\n","\n","generator =[]\n","\n","generator.extend([ # explode dimensionality\n","                   Flatten(),\n","                   Dense(INIT_KERNELS * INIT_IMAGE_SIZE * INIT_IMAGE_SIZE, activation=\"relu\", input_dim=Z_SIZE, kernel_initializer=init),\n","                   Reshape((INIT_IMAGE_SIZE, INIT_IMAGE_SIZE, INIT_KERNELS))\n","                   ])\n","\n","for i in range(UP_SAMPLING_LAYERS):\n","    generator.extend([ # augment resolution x2\n","                      UpSampling2D(),\n","                      Conv2D(int(INIT_KERNELS / 2**i), kernel_size=5, padding=\"same\", kernel_initializer=init),\n","                      BatchNormalization(momentum=0.8),\n","                      Activation(\"relu\")\n","                      ])\n","\n","generator.extend([ # compose final image\n","                   Conv2D(IMAGE_CHANNELS, kernel_size=5, padding=\"same\", kernel_initializer=init),\n","                   Activation(\"tanh\")\n","                   ])\n","\n","discrimenator = [ # convolution block 1\n","                  Conv2D(16, kernel_size=3, strides=2, padding=\"same\", kernel_constraint=const, kernel_initializer=init, input_shape=DIMS),\n","                  BatchNormalization(momentum=0.8),\n","                  LeakyReLU(alpha=0.2),\n","                  Dropout(0.25),\n","                  # convolution block 2\n","                  Conv2D(32, kernel_size=3, strides=2, padding=\"same\", kernel_constraint=const, kernel_initializer=init),\n","                  ZeroPadding2D(padding=((0,1),(0,1))),\n","                  BatchNormalization(momentum=0.8),\n","                  LeakyReLU(alpha=0.2),\n","                  Dropout(0.25),\n","                  # convolution block 3\n","                  Conv2D(64, kernel_size=3, strides=2, padding=\"same\", kernel_constraint=const, kernel_initializer=init),\n","                  BatchNormalization(momentum=0.8),\n","                  LeakyReLU(alpha=0.2),\n","                  Dropout(0.25),\n","                  # block 4\n","                  Conv2D(128, kernel_size=3, strides=1, padding=\"same\", kernel_constraint=const, kernel_initializer=init),\n","                  BatchNormalization(momentum=0.8),\n","                  LeakyReLU(alpha=0.2),\n","                  Dropout(0.25),\n","                  Flatten(),\n","                  Dense(1, kernel_constraint=const, kernel_initializer=init)\n","                  ]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2w-E1pAF-1_F","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Compile the model with its optimizers\n","\n","from tensorflow.keras.optimizers import RMSprop, Adam\n","\n","ALPHA = 0.00005 #@param {type:\"number\"}\n","\n","# optimizers\n","gen_optimizer = RMSprop(lr=ALPHA)\n","disc_optimizer = RMSprop(lr=ALPHA)\n","# model\n","model = WGAN(name=f'WGAN_{DATASET.upper()}',\n","             gen = generator,\n","             disc = discrimenator,\n","             gen_optimizer = gen_optimizer,\n","             disc_optimizer = disc_optimizer,\n","             z_size = Z_SIZE\n","             )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b90-eROYKmQF","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Third party functions for saving model and plots\n","\n","from IPython.display import clear_output\n","\n","SAVE_LINES = 10 #@param {type:\"integer\"}\n","SAVE_ROWS = 10 #@param {type:\"integer\"}\n","\n","# evaluate the discrimenator, plot generated images, save generator model\n","def summarize_performance(epoch, model, losses):\n","    # a simple summerizing print\n","    print(f\"Epoch: {epoch+1} | disc_loss: {losses.discrimenator_loss.values[-1]} | gen_loss: {losses.generator_loss.values[-1]}\")\n","    # save plot\n","    save_plot(epoch, model)\n","    # save history\n","    save_history(losses)\n","    # save the model\n","    save_model(epoch, model)\n","\n","# create and save a plot of generated images (reversed grayscale)\n","def save_plot(epoch, model, n_lines=SAVE_LINES, n_rows=SAVE_ROWS, z_size=Z_SIZE):\n","    # prepare noise\n","    noise = tf.random.normal(shape=(n_lines*n_rows, z_size))\n","    # generate images\n","    samples = model.generate(noise)\n","    # scale from [-1,1] to [0,1]\n","    samples = (samples + 1.) / 2.\n","    # prepare plot\n","    for i in range(n_lines * n_rows):\n","        # define subplot\n","        pyplot.subplot(n_lines, n_rows, 1 + i)\n","        # turn off axis\n","        pyplot.axis('off')\n","        # plot raw pixel data\n","        pyplot.imshow(tf.squeeze(samples[i, :, :, :]), cmap='gray_r')\n","    # save plot to file\n","    file_name = 'plots/%s/WGAN/WGAN_%s_plot_e%03d.png' % (DATASET.upper(), DATASET.upper(), epoch+1)\n","    pyplot.savefig(file_name)\n","    # pyplot.show()\n","    pyplot.close()\n","\n","# save the whole model if possible xD\n","def save_model(epoch, model):\n","    file_name = 'models/%s/WGAN/WGAN_%s_model_e%03d.weights' % (DATASET.upper(), DATASET.upper(), epoch+1)\n","    model.save_weights(file_name)\n","\n","def save_history(losses):\n","    # plot history\n","    pyplot.plot(losses.discrimenator_loss.values, label='discrimenator_loss')\n","    pyplot.plot(losses.generator_loss.values, label='generator_loss')\n","    pyplot.legend()\n","    pyplot.savefig('plots/%s/WGAN/WGAN_%s_loss_history.png' % (DATASET.upper(), DATASET.upper()))\n","    pyplot.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"d552b8aa-e724-4cd2-a459-c1b8046a5515","cellView":"both","executionInfo":{"status":"ok","timestamp":1583882698003,"user_tz":-60,"elapsed":2559,"user":{"displayName":"ilyas moutawwakil","photoUrl":"","userId":"11714869551917393786"}},"id":"Wo4lnvfwjSEn","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#@title Start training\n","\n","import numpy as np\n","from tqdm import tqdm\n","from pandas import DataFrame\n","\n","EPOCHS =  100   #@param {type:\"integer\"}\n","BATCH_SIZE = 64 #@param {type:\"integer\"}\n","\n","TRAIN_BUF = len(train_images)\n","TRAIN_BATCHES =int(TRAIN_BUF/BATCH_SIZE)\n","\n","# a pandas dataframe to save the loss information to\n","losses = DataFrame(columns = ['discrimenator_loss', 'generator_loss'])\n","\n","# iterate through epochs\n","for epoch in range(EPOCHS):\n","    # initiate loss counter\n","    loss = []\n","    # train through the dataset\n","    for batch in tqdm(range(TRAIN_BATCHES)):\n","        # take random indexes\n","        ix = np.random.randint(0, TRAIN_BUF, BATCH_SIZE)\n","        # select images\n","        train_x = train_images[ix]\n","        # train discriminator\n","        disc_loss = model.train_disc(train_x, BATCH_SIZE)\n","        # train generator\n","        gen_loss = model.train_gen(BATCH_SIZE)\n","        # \n","        loss.append((disc_loss, gen_loss))\n","    \n","    # \n","    losses.loc[len(losses)] = np.mean(loss, axis=0)\n","    # clear previous results\n","    clear_output()\n","    # plot new results\n","    summarize_performance(epoch, model, losses)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 100 | disc_loss: 1.2097702040136937e-07 | gen_loss: 0.01941424421966076\n"],"name":"stdout"}]}]}